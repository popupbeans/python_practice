{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>機械学習課題 9 : Logistic Regression ロジスティック回帰 Part 2 - Better to use great libraries</h3><br/>\n",
    "\n",
    "<h4>注意 : pythonコードを実行しながら読んでください!</h4><br/>\n",
    "\n",
    "前回の課題ではロジスティック回帰(Logistic Regression)での目的関数(Cost Function)と最急降下法(Gradient Descent)のコードを作成してみましたが、最急降下法(Gradient Descent)の処理で結構時間がかかっていたところが気になります。\n",
    "\n",
    "実は、機械学習コードを作成するには、自分で全部作るよりは、既に作られている優秀なライブラリーを活用した方がとても効率的です。例えば、今回の場合、Scikitライブラリーには既に最急降下法(Gradient Descent)用の関数が存在していますので、これを使えば、コードも簡単に作成できますし、性能ももっと良いです。\n",
    "\n",
    "今回の課題ではScikitライブラリーの$minimize$という関数を使ってもっと簡単で、実装処理ももっと速いコードを作成してみます。\n",
    "\n",
    "<h4>まず、前回作成した$sigmoid$、$costFunction$関数を持ってきてください。</h4>\n",
    "\n",
    "<h4>コード作成後、実行すると、自動採点を行います。$Correct$が表示されると問題ありません。</h4>\n",
    "\n",
    "注意：\n",
    "以下の部分にコードを書いてください。\n",
    "#------- Coding Start -------\n",
    "#------- Coding End -------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "#read learning data X and Y\n",
    "data = np.loadtxt('ex8data1.txt', delimiter=',')\n",
    "\n",
    "# Change data form for matrix calculation\n",
    "X = np.c_[np.ones((data.shape[0],1)),data[:,0:2]]\n",
    "Y = np.c_[data[:,2]]\n",
    "\n",
    "# Sigmoid Function\n",
    "def sigmoid(z):\n",
    "    y = z # initialize value to avoid error\n",
    "       \n",
    "    # ------- Coding Start -------    \n",
    "\n",
    "    # ------- Coding End -------\n",
    "    \n",
    "    return np.asarray(y,dtype=np.float64)\n",
    "\n",
    "# Cost Function\n",
    "def costFunction(theta, X, Y):\n",
    "    J = 0\n",
    "    m = Y.size\n",
    "        \n",
    "    # ------- Coding Start -------    \n",
    "\n",
    "    # ------- Coding End -------\n",
    "         \n",
    "    if np.isnan(J[0]) :\n",
    "        return (np.inf)\n",
    "    return (J[0])\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "# Evaluation\n",
    "#-----------------------------------------------------------\n",
    "def evaluateCost(value, min, max):\n",
    "    print(\"J = \", value, \" => Correct\") if value > min and value < max else print(\"J = \", value, \" => Wrong\")\n",
    "\n",
    "theta = np.zeros((X.shape[1],1))\n",
    "evaluateCost(costFunction(theta, X, Y),0.6931471,0.6931472)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまでは前回と一緒ですが、最急降下法(Gradient Descent)の部分だけScikitの$minimize$関数を使う形に変えてみます。$minimize$関数を使う場合は、学習率など細かいパラメーターの調整に困ることなく、関数にやってもらいますので、よりコード作成作業が簡単になります。\n",
    "\n",
    "$minimize$関数を使うには最急降下法(Gradient Descent)数式の一部だけ必要です。前回は以下の式全部作成する必要がありました。\n",
    "\n",
    "$$New \\theta_j = Current \\theta_j - \\alpha * \\frac{\\Delta}{\\Delta \\theta_j} J = Current \\theta_j - \\alpha * \\frac{1}{m} * \\sum_{i=1}^m(g(X^i) - Y^i)X_j^i$$\n",
    "\n",
    "しかし、今回は$\\frac{\\Delta}{\\Delta \\theta_j} J$の部分だけ作成し、$minimize$関数の$jac$というパラメーターに渡せば十分です。\n",
    "\n",
    "$$\\frac{\\Delta}{\\Delta \\theta_j} J = \\frac{1}{m} * \\sum_{i=1}^m(g(X^i) - Y^i)X_j^i$$\n",
    "\n",
    "$minimize$関数の詳細については以下を参考にしてください。（ライブラリー自体はimport済みです。）\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html\n",
    "\n",
    "<h4>ここで新しい最急降下法(Gradient Descent)用の関数$gradientDescentForMinimize$を作成してみましょう。</h4>\n",
    "\n",
    "<h4>コード作成後、実行すると、自動採点を行います。$Correct$が表示されると問題ありません。</h4>\n",
    "\n",
    "注意：\n",
    "以下の部分にコードを書いてください。\n",
    "#------- Coding Start -------\n",
    "#------- Coding End -------\n",
    "\n",
    "$minimize$関数のコールについては、既にコードに書いておきましたので、以下のコードを実行すれば、学習処理まで全部やってくれます。コード上の関数の動作を簡単に説明すると、$init_theta$の値から始め、$costFunction$の出力が最小化される最適パラメーター$theta$を見つけてくれます。（新しいパラメーター$theta$は$minimize$関数のアウトプットの$x$パラメーターとして戻ってきます。）\n",
    "\n",
    "あとは、$minimize$関数が見つけた決定境界 (decision boundary)まで表示しますので、前回自分が作成したグラフと比較してみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent Function\n",
    "def gradientDescentForMinimize(theta, X, Y):\n",
    "    m = Y.size\n",
    "    grad = []\n",
    "  \n",
    "    # ------- Coding Start -------\n",
    "\n",
    "    # ------- Coding End -------\n",
    "       \n",
    "    return (grad.flatten())\n",
    "\n",
    "# Call minimize function - Learning by minimize function from Scikit\n",
    "init_theta = np.zeros(X.shape[1])\n",
    "res = minimize(costFunction, init_theta, args=(X,Y), method=None, jac=gradientDescentForMinimize, options={'maxiter':400})\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "# Evaluation\n",
    "#-----------------------------------------------------------\n",
    "def evaluateCost(value, min, max):\n",
    "    print(\"Minimized J = \", value, \" => Correct\") if value > min and value < max else print(\"Minimized J = \", value, \" => Wrong\")\n",
    "\n",
    "theta = np.zeros((X.shape[1],1))\n",
    "evaluateCost(res.fun,0.2034977015895,0.20349770158952)\n",
    "\n",
    "negative = data[:,2] == 0\n",
    "positive = data[:,2] == 1\n",
    "\n",
    "plt.scatter(data[positive][:,0],data[positive][:,1], marker = 'o', c = 'r')\n",
    "plt.scatter(data[negative][:,0],data[negative][:,1], marker = 'x', c = 'b')\n",
    "\n",
    "xx = np.arange(30,100)\n",
    "yy = -1 * (1 * res.x[0] + xx * res.x[1]) / res.x[2]\n",
    "plt.plot(xx, yy, c = 'g')\n",
    "\n",
    "plt.xlabel(\"X1 : Exam 1 Score\")\n",
    "plt.ylabel(\"X2 : Exam 2 Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果はいかがでしょうか。自分が作成したコードよりもっと速く処理できましたか。\n",
    "\n",
    "<h5>（RuntimeWarning: divide by zero encountered in logが発生したら、それはpythonの小数点のprecision問題でlog関数へのインプットにゼロが含まれたのが原因です。無視してもいいと思います。）</h5>\n",
    "\n",
    "グラフ自体は多分前回自分が作成した物とほぼ変わらないと思います。Scikit自体はすごく難しい数学モデル処理に使われるものですが、我々は機械学習の決まっているパターン通りシンプルに考えて必要な部分だけ使って良いです。\n",
    "\n",
    "あと、念の為$minimize$関数のアウトプットの中身も確認しておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print result\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>一つだけ、まだちょっと気になるところがあります。</h4>\n",
    "\n",
    "上のグラフを見るとまだ正しく分類されていないデータが見えますね。赤いマルが決定境界 (decision boundary)の下にあったり、青いバツが上にあったりしています。\n",
    "\n",
    "まだ我々が作った推論モデルの精度が高くないですかね。具体的に現在のモデルの精度を定量化してみましょう。単純に”このモデルは品質悪いよ！”と主張するよりは、”正答率XX%だから品質悪いよ！”と言った方がもっとプロの姿に近いですからね。（笑）\n",
    "\n",
    "<h4>その為、ここで課題です。まず、この推論モデルを使って、インプットのテスト成績に対した資格取得可能性を推論するAIエンジンを作ってみます。\n",
    "\n",
    "<h4>コード作成後、実行すると、自動採点を行います。4回$Correct$が表示されると問題ありません。</h4>\n",
    "\n",
    "注意：\n",
    "以下の部分にコードを書いてください。\n",
    "#------- Coding Start -------\n",
    "#------- Coding End -------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(theta, X, threshold = 0.5):\n",
    "    p = 0\n",
    "    \n",
    "    #------- Coding Start -------\n",
    "\n",
    "    #------- Coding Start -------\n",
    "    \n",
    "    return p.astype('int')\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "# Evaluation\n",
    "#-----------------------------------------------------------\n",
    "def evaluatePredict(value, result):\n",
    "    print(\"Predicted Result = \", value, \" => Correct\") if value == result else print(\"Predicted Result = \", value, \" => Wrong\")\n",
    "\n",
    "evaluatePredict(predict(res.x, np.array([1, 45, 85])),1)\n",
    "evaluatePredict(predict(res.x, np.array([1, 70, 50])),0)\n",
    "evaluatePredict(predict(res.x, np.array([1, 35, 90])),1)\n",
    "evaluatePredict(predict(res.x, np.array([1, 100, 20])),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>あと続いて、推論モデルの正答率を計算する関数を作成してみましょう。</h4>\n",
    "\n",
    "<h4>コード作成後、実行すると、自動採点を行います。$Correct$が表示されると問題ありません。</h4>\n",
    "\n",
    "注意：\n",
    "以下の部分にコードを書いてください。\n",
    "#------- Coding Start -------\n",
    "#------- Coding End -------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(theta, X, Y, threshold = 0.5):\n",
    "    accu = 0.0\n",
    "    m = Y.size\n",
    "    \n",
    "    p = sigmoid(X.dot(theta.T)) >= threshold\n",
    "    \n",
    "    #------- Coding Start -------\n",
    "\n",
    "    #------- Coding End -------\n",
    "    \n",
    "    return accu\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "# Evaluation\n",
    "#-----------------------------------------------------------\n",
    "def evaluateAccuracy(value, result):\n",
    "    print(\"Accuracy = %3d%%\"%(value * 100), \" => Correct\") if value >= result else print(\"Accuracy = %3d%%\"%(value * 100), \" => Wrong\")\n",
    "    \n",
    "evaluateAccuracy(accuracy(res.x, X, Y),0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正答率はいかがでしょうか。ちょっと不満を持つ値になってしまいましたが、次の課題で改善する方法を練習してみましょう。\n",
    "<h4>大変お疲れ様でした！</h4>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
